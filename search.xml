<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Nginx配置</title>
    <url>/2020/03/10/Nginx%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="查看Nginx配置"><a href="#查看Nginx配置" class="headerlink" title="查看Nginx配置"></a>查看Nginx配置</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nginx -V</span><br><span class="line">nginx version: nginx&#x2F;1.8.0</span><br><span class="line">built by clang 7.0.0 (clang-700.0.72)</span><br><span class="line">built with OpenSSL 1.0.2d 9 Jul 2015</span><br><span class="line">TLS SNI support enabled</span><br><span class="line"> </span><br><span class="line">configure arguments:</span><br><span class="line">--prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;nginx&#x2F;1.8.0</span><br><span class="line">--with-http_ssl_module</span><br><span class="line">--with-pcre</span><br><span class="line">--with-ipv6</span><br><span class="line">--sbin-path&#x3D;&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;nginx&#x2F;1.8.0&#x2F;bin&#x2F;nginx</span><br><span class="line">--with-cc-opt&#x3D;&#39;-I&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;pcre&#x2F;8.37&#x2F;include -I&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;openssl&#x2F;1.0.2d_1&#x2F;include&#39;</span><br><span class="line">--with-ld-opt&#x3D;&#39;-L&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;pcre&#x2F;8.37&#x2F;lib -L&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;openssl&#x2F;1.0.2d_1&#x2F;lib&#39;</span><br><span class="line">--conf-path&#x3D;&#x2F;usr&#x2F;local&#x2F;etc&#x2F;nginx&#x2F;nginx.conf</span><br><span class="line">--pid-path&#x3D;&#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;nginx.pid</span><br><span class="line">--lock-path&#x3D;&#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;nginx.lock</span><br><span class="line">--http-client-body-temp-path&#x3D;&#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;nginx&#x2F;client_body_temp</span><br><span class="line">--http-proxy-temp-path&#x3D;&#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;nginx&#x2F;proxy_temp</span><br><span class="line">--http-fastcgi-temp-path&#x3D;&#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;nginx&#x2F;fastcgi_temp</span><br><span class="line">--http-uwsgi-temp-path&#x3D;&#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;nginx&#x2F;uwsgi_temp</span><br><span class="line">--http-scgi-temp-path&#x3D;&#x2F;usr&#x2F;local&#x2F;var&#x2F;run&#x2F;nginx&#x2F;scgi_temp</span><br><span class="line">--http-log-path&#x3D;&#x2F;usr&#x2F;local&#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log</span><br><span class="line">--error-log-path&#x3D;&#x2F;usr&#x2F;local&#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log</span><br><span class="line">--with-http_gzip_static_module</span><br></pre></td></tr></table></figure>
<p>注意上面的几个配置：</p>
<ul>
<li>–conf-path : /usr/local/etc/nginx/nginx.conf 配置文件</li>
<li>–http-log-path：访问日志</li>
<li>–error-log-path：错误日志</li>
</ul>
<h1 id="nginx-conf配置文件"><a href="#nginx-conf配置文件" class="headerlink" title="nginx.conf配置文件"></a>nginx.conf配置文件</h1><p>前面我们知道了，/usr/local/etc/nginx/nginx.conf 是nginx服务运行过程中的具体配置文件<br>这一部分，我们将通过剖析nginx.conf文件，弄清下面几点：</p>
<ol>
<li>设置端口？</li>
<li>开启日志？修改日志存储路径？</li>
<li>配置反向代理映射规则？</li>
</ol>
<h2 id="文件内部结构"><a href="#文件内部结构" class="headerlink" title="文件内部结构"></a>文件内部结构</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#user  nobody;</span><br><span class="line">worker_processes  1;</span><br><span class="line"> </span><br><span class="line">#error_log  logs&#x2F;error.log;</span><br><span class="line">#error_log  logs&#x2F;error.log  notice;</span><br><span class="line">#error_log  logs&#x2F;error.log  info;</span><br><span class="line"> </span><br><span class="line">#pid        logs&#x2F;nginx.pid;</span><br><span class="line">  </span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application&#x2F;octet-stream;</span><br><span class="line"> </span><br><span class="line">    #log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;</span><br><span class="line">    #                  &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;</span><br><span class="line">    #                  &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;</span><br><span class="line"> </span><br><span class="line">    #access_log  logs&#x2F;access.log  main;</span><br><span class="line"> </span><br><span class="line">    sendfile        on;</span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"> </span><br><span class="line">    #keepalive_timeout  0;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"> </span><br><span class="line">    #gzip  on;</span><br><span class="line"> </span><br><span class="line">    server &#123;</span><br><span class="line">        listen       8080;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"> </span><br><span class="line">        #charset koi8-r;</span><br><span class="line"> </span><br><span class="line">        #access_log  logs&#x2F;host.access.log  main;</span><br><span class="line"> </span><br><span class="line">        location &#x2F; &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        #error_page  404              &#x2F;404.html;</span><br><span class="line"> </span><br><span class="line">        # redirect server error pages to the static page &#x2F;50x.html</span><br><span class="line">        #</span><br><span class="line">        error_page   500 502 503 504  &#x2F;50x.html;</span><br><span class="line">        location &#x3D; &#x2F;50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        # proxy the PHP scripts to Apache listening on 127.0.0.1:80</span><br><span class="line">        #</span><br><span class="line">        #location ~ \.php$ &#123;</span><br><span class="line">        #    proxy_pass   http:&#x2F;&#x2F;127.0.0.1;</span><br><span class="line">        #&#125;</span><br><span class="line"> </span><br><span class="line">        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000</span><br><span class="line">        #</span><br><span class="line">        #location ~ \.php$ &#123;</span><br><span class="line">        #    root           html;</span><br><span class="line">        #    fastcgi_pass   127.0.0.1:9000;</span><br><span class="line">        #    fastcgi_index  index.php;</span><br><span class="line">        #    fastcgi_param  SCRIPT_FILENAME  &#x2F;scripts$fastcgi_script_name;</span><br><span class="line">        #    include        fastcgi_params;</span><br><span class="line">        #&#125;</span><br><span class="line"> </span><br><span class="line">        # deny access to .htaccess files, if Apache&#39;s document root</span><br><span class="line">        # concurs with nginx&#39;s one</span><br><span class="line">        #</span><br><span class="line">        #location ~ &#x2F;\.ht &#123;</span><br><span class="line">        #    deny  all;</span><br><span class="line">        #&#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    # another virtual host using mix of IP-, name-, and port-based configuration</span><br><span class="line">    #</span><br><span class="line">    #server &#123;</span><br><span class="line">    #    listen       8000;</span><br><span class="line">    #    listen       somename:8080;</span><br><span class="line">    #    server_name  somename  alias  another.alias;</span><br><span class="line"> </span><br><span class="line">    #    location &#x2F; &#123;</span><br><span class="line">    #        root   html;</span><br><span class="line">    #        index  index.html index.htm;</span><br><span class="line">    #    &#125;</span><br><span class="line">    #&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">    # HTTPS server</span><br><span class="line">    #</span><br><span class="line">    #server &#123;</span><br><span class="line">    #    listen       443 ssl;</span><br><span class="line">    #    server_name  localhost;</span><br><span class="line"> </span><br><span class="line">    #    ssl_certificate      cert.pem;</span><br><span class="line">    #    ssl_certificate_key  cert.key;</span><br><span class="line"> </span><br><span class="line">    #    ssl_session_cache    shared:SSL:1m;</span><br><span class="line">    #    ssl_session_timeout  5m;</span><br><span class="line"> </span><br><span class="line">    #    ssl_ciphers  HIGH:!aNULL:!MD5;</span><br><span class="line">    #    ssl_prefer_server_ciphers  on;</span><br><span class="line"> </span><br><span class="line">    #    location &#x2F; &#123;</span><br><span class="line">    #        root   html;</span><br><span class="line">    #        index  index.html index.htm;</span><br><span class="line">    #    &#125;</span><br><span class="line">    #&#125;</span><br><span class="line">    include servers&#x2F;*;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>nginx.conf文件内部结构：</p>
<ol>
<li>worker_processes</li>
<li>error_log</li>
<li>events</li>
<li>http<ol>
<li>access_log</li>
<li>server<ol>
<li>listen</li>
<li>server_name</li>
<li>access_log</li>
<li>location<br>注：https时，上面的server配置略有不同。</li>
</ol>
</li>
</ol>
</li>
</ol>
<h2 id="静态资源"><a href="#静态资源" class="headerlink" title="静态资源"></a>静态资源</h2><p>系统设计时，动态资源、静态资源，要在url上能够区分出来，这样才能使用nginx为静态资源提供单独的映射关系。<br>举例：下面就是动静资源分离的简单配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        root &#x2F;data&#x2F;www;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    location &#x2F;images&#x2F; &#123;</span><br><span class="line">        root &#x2F;data;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="动态资源"><a href="#动态资源" class="headerlink" title="动态资源"></a>动态资源</h2><p>对于动态资源，nginx一般会把request转发到相应的服务器。<br>举例：下面把动态资源转发到其他服务器，静态资源直接指向本地。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        proxy_pass http:&#x2F;&#x2F;localhost:8080&#x2F;;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    location ~ \.(gif|jpg|png)$ &#123;</span><br><span class="line">        root &#x2F;data&#x2F;images;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，location使用了process_pass配置，当proxy_pass指向多个ip地址时，可以使用 server group 配置，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">upstream backend &#123;</span><br><span class="line">    server backend1.example.com       weight&#x3D;5;</span><br><span class="line">    server backend2.example.com:8080;</span><br><span class="line">    server unix:&#x2F;tmp&#x2F;backend3;</span><br><span class="line"> </span><br><span class="line">    server backup1.example.com:8080   backup;</span><br><span class="line">    server backup2.example.com:8080   backup;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">server &#123;</span><br><span class="line">    location &#x2F; &#123;</span><br><span class="line">        proxy_pass http:&#x2F;&#x2F;backend;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>Nginx原理</title>
    <url>/2020/03/10/Nginx%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>引用：</p>
<ul>
<li><a href="http://ningg.top/nginx-series-principle/" target="_blank" rel="noopener">http://ningg.top/nginx-series-principle/</a></li>
</ul>
<h1 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h1><h2 id="Nginx的进程模型"><a href="#Nginx的进程模型" class="headerlink" title="Nginx的进程模型"></a>Nginx的进程模型</h2><p><img src="/images/nginx-multi-progress-model.png" alt=""><br>Nginx服务器，正常运行过程中：</p>
<ol>
<li><strong>多进程</strong>：1个Master进程、多个Worker进程；</li>
<li><strong>Master进程</strong>：管理多个Worker进程：<ol>
<li>对外接口：接收<strong>外部操作</strong>信号</li>
<li>对内转发：根据<strong>外部操作</strong>的不同，通过<strong>信号</strong>管理Worker</li>
<li>监控：监控Worker进程的运行状态，Worker进程异常终止后，自动重启Worker进程</li>
</ol>
</li>
<li><strong>Worker</strong>进程：所有Worker进程都是平等的：<ol>
<li>实际处理：网络请求，又Worker进程处理；</li>
<li>Worker进程数量：在nginx.conf中配置，一般设置为<strong>CPU核心数</strong>，充分利用CPU资源，同时避免进程数量过多，避免进程之间竞争CPU资源，增加上下文切换的损耗。</li>
</ol>
</li>
</ol>
<p>思考：</p>
<ol>
<li>请求是连接到Nginx，Master进程负责处理和转发？</li>
<li>如何选定哪个Worker进程处理请求？请求的处理结果，是否还要经过Master进程？</li>
</ol>
<p><img src="/images/nginx-master-worker-details.png" alt=""></p>
<p>HTTP连接建立和请求处理过程：</p>
<ol>
<li>Nginx启动时，Master进程，加载配置文件；</li>
<li>Master进程，初始化监听的socket；</li>
<li>Master进程，fork出多个Worker进程；</li>
<li>Worker进程，竞争新的连接，获胜方通过三次握手，建立Socket连接，并处理请求。</li>
</ol>
<p>Nginx高性能、高并发：</p>
<ol>
<li>Nginx采用：<strong>多进程</strong>+<strong>异步非阻塞</strong>方式（<strong>IO多路复用</strong>epool）</li>
<li>请求的完整过程：<ol>
<li>建立连接</li>
<li>读取请求：解析请求</li>
<li>处理请求</li>
<li>相应请求</li>
</ol>
</li>
<li>请求的完整过程，对应到低层，就是：读写socket事件</li>
</ol>
<h2 id="Nginx的事件处理模型"><a href="#Nginx的事件处理模型" class="headerlink" title="Nginx的事件处理模型"></a>Nginx的事件处理模型</h2><p>request：Nginx中的http请求。<br>基本的HTTP Web Server工作模式：</p>
<ol>
<li><strong>接受请求</strong>：逐行读取<strong>请求行</strong>和<strong>请求头</strong>，判断有请求体后，读取<strong>请求体</strong></li>
<li><strong>处理请求</strong></li>
<li><strong>返回响应</strong>：根据处理结果，生成相应的HTTP请求（<strong>响应行</strong>、<strong>响应头</strong>、<strong>响应体</strong>）</li>
</ol>
<p>Nginx也是这个套路，整体流程一致：<br><img src="/images/nginx-request-process-model.png" alt=""></p>
<h2 id="模块化体系结构"><a href="#模块化体系结构" class="headerlink" title="模块化体系结构"></a>模块化体系结构</h2><p><img src="/images/nginx-architecture.png" alt=""><br>nginx的模块根据其功能基本上可以分为以下几种类型：</p>
<ul>
<li><strong>event module</strong>：搭建了独立于操作系统的事件处理的框架，及提供了各具体时间的处理。包括ngx_events_module,ngx_event_core_module和ngx_epool_module等。nginx具体使用何种时间处理模块，这依赖于具体的操作系统和编译选项。</li>
<li><strong>phase handler</strong>：此类型的模块也被直接成为handler模块。主要负责处理客户端请求并产生待相应内容，比如ngx_http_static_module模块，负责客户端的静态页面请求处理并将对应的磁盘文件准备为响应内容输出。</li>
<li><strong>output filter</strong>：也被成为filter模块，主要是负责对输出的内容进行处理，可以对输出进行修改。例如，可以实现对输出的所有html页面增加预定义的footbar一类的工作，或者对输出的图片的URL进行替换之类的工作。</li>
<li><strong>upstream</strong>：upstream模块实现反向代理的功能，将真正的请求转发到后端服务器上，并从后端服务器上读取相应，发回客户端。upstream模块是一种特殊的handler，只不过相应内容不是真正由自己产生的，而是从后端服务器上读取的。</li>
<li><strong>load-balancer</strong>：负载均衡，实现特定的算法，在众多的后端服务器中，选择一个服务器出来作为某个请求的转发服务器。</li>
</ul>
]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx限速模块探讨</title>
    <url>/2020/03/09/Nginx%E9%99%90%E9%80%9F%E6%A8%A1%E5%9D%97%E6%8E%A2%E8%AE%A8/</url>
    <content><![CDATA[<p>Nginx限速模块探讨，引用：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/32391675" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32391675</a></li>
<li><a href="http://tengine.taobao.org/book/index.html" target="_blank" rel="noopener">http://tengine.taobao.org/book/index.html</a></li>
</ul>
<h1 id="核心算法"><a href="#核心算法" class="headerlink" title="核心算法"></a>核心算法</h1><p>在探讨Nginx限速模块之前，我们先来看看网络传输中常用两个的流量控制算法：漏桶算法和令牌桶算法。</p>
<h2 id="漏桶算法（leaky-bucket）"><a href="#漏桶算法（leaky-bucket）" class="headerlink" title="漏桶算法（leaky bucket）"></a>漏桶算法（leaky bucket）</h2><p>漏桶算法（leaky bucket）思想如图所示：<br><img src="/images/v2-2ff7a9dbc1242a4c1abf960efe116813_r.jpg" alt=""><br>一个形象的解释是：</p>
<ul>
<li>水（请求）从上方倒入水桶，从水桶下方流出（被处理）；</li>
<li>来不及流出的水存在水桶中（缓冲），同时水桶中的水以<strong>固定速率</strong>流出；</li>
<li>水桶满后，水溢出（丢弃）。<br>这个算法的核心是：缓存请求、匀速处理、多余的请求直接丢弃。</li>
</ul>
<h2 id="令牌桶算法（token-bucket）"><a href="#令牌桶算法（token-bucket）" class="headerlink" title="令牌桶算法（token bucket）"></a>令牌桶算法（token bucket）</h2><p>令牌桶算法（token bucket）思想如图所示：<br><img src="/images/v2-fe9b3489d9c7a462b5594faf2a80266b_r.jpg" alt=""><br>算法思想是：</p>
<ul>
<li>令牌以固定的速率产生，并缓存到令牌桶中；</li>
<li>令牌桶放满时，多余的令牌被丢弃；</li>
<li>请求要消耗等比例的令牌才能被处理（处理多少请求，消耗多少令牌）；</li>
<li>令牌不够时，请求被缓存。</li>
</ul>
<p>相比漏桶算法，令牌桶算法不同之处在于它不但有一只“桶”，还有个队列，这个桶是用来存放令牌的，队列才是用来存放请求的。</p>
<p>从作用上来说，漏桶算法和令牌桶算法最明显的区别就是是否允许<strong>突发流量（burst</strong>的处理，漏桶算法能够<strong>强行限制数据的实时传输（处理）速率</strong>，对突发流量不做额外处理；而令牌桶算法能够在<strong>限制数据的平均传输速率的同时允许某种程度的突发传输</strong>。</p>
<p>Nginx按请求速率限速模块使用的是漏桶算法，即能够强行保证请求的实时处理速度不会超过设置的阀值。</p>
<h1 id="Nginx限速模块"><a href="#Nginx限速模块" class="headerlink" title="Nginx限速模块"></a>Nginx限速模块</h1><p>Nginx主要有两种限速方式：按连接数限速（ngx_http_limit_conn_module）、按请求速率限速（ngx_http_limit_req_module）。我们着重讲解按请求速率限速。</p>
<h2 id="按连接数限速"><a href="#按连接数限速" class="headerlink" title="按连接数限速"></a>按连接数限速</h2><p>按连接数限速是指限制单个IP（或者其他的key）同时发起的连接数，超出这个限制后，Nginx将直接拒绝更多的连接。这个模块的配置比较好理解，详见<a href="http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html" target="_blank" rel="noopener">ngx_http_limit_conn_module官方文档”</a>。</p>
<h2 id="按请求速率限速"><a href="#按请求速率限速" class="headerlink" title="按请求速率限速"></a>按请求速率限速</h2><p>按请求速率限速是指限制单个IP（或者其他的Key）发送请求的速率，超出指定速率后，Nginx将直接拒绝更多的请求。采用<strong>leaky bucket</strong>算法实现。为深入理解这个模块，我们先从实验现象说起。开始之前我们先简单介绍一个该模块的配置方式，以下面的配置为例：<br><img src="/images/v2-4711d21160627b6aec17baefc8aa3374_720w.jpg" alt=""><br>使用 limit_req_zone 关键字，我们定义一个名为mylimit大小为10MB的共享内存区域（zone），用来存放限速相关的统计信息，限速的 Key 值为二进制的IP地址（$binary_remote_addr），限速上限（rate）为 2r/s；接着我们使用 limit_req 关键字将上述规则作用到 /search/ 上。 burst 和 nodelay 的作用稍后解释。</p>
<p>使用上述规则，对于 /search/ 目录的访问，单个IP的访问速度被限制在2请求/秒，超过这个限制的访问将直接被Nginx拒绝。</p>
<h3 id="实验1—毫秒级统计"><a href="#实验1—毫秒级统计" class="headerlink" title="实验1—毫秒级统计"></a>实验1—毫秒级统计</h3><p>我们有如下配置：<br><img src="/images/v2-3dd07cea19be343996f01cfbe276feac_720w.jpg" alt=""><br>上述规则限制了每个IP访问的速度为2r/s，并将该规则作用于跟目录。如果单个IP在非常短的时间内并发发送多个请求，结果会怎样呢？<br><img src="/images/v2-fa8d8095439c4391ef426190c0449c89_720w.jpg" alt=""><br>我们使用单个IP在10ms内并发，并发送了6个请求，只有1个成功，剩下的5个都被拒绝。我们设置的速度是2r/s，为什么只有1个成功呢？<strong>是因为Nginx的限速统计是基于毫秒的，我们限制的速度是2r/s，转换一下就是500ms内单个IP只允许通过1个请求</strong>，从501ms开始才允许通过第二个请求。<br><img src="/images/v2-a923be79e5bfb07aa0e0540c718a967a_720w.jpg" alt=""></p>
<h3 id="实验2—burst允许缓存处理突发请求"><a href="#实验2—burst允许缓存处理突发请求" class="headerlink" title="实验2—burst允许缓存处理突发请求"></a>实验2—burst允许缓存处理突发请求</h3><p>实验1中我们看到，短时间内发送了大量的请求，Nginx按照毫秒级精度统计，超出限制的请求直接拒绝。这在实际场景中未免过于苛刻，真实网络环境中请求到来不是匀速的，很可能有请求“突发”的情况。Nginx考虑到了这种情况，可以通过<strong>burst</strong>关键字开启对突发请求的缓存处理，而不是直接拒绝。<br>来看我们的配置：<br><img src="/images/v2-2121faf3d728d14e88f9fdb71e84d114_720w.jpg" alt=""><br>我们加入了<strong>burst=4</strong>，意思是每个key（此处是每个IP）最多允许4个突发请求的到来。如果单个IP在10ms内发送6个请求，结果会怎样呢？<br><img src="/images/v2-70b29aa0d30abec245bdea38088d7ded_720w.jpg" alt=""><br>相比实验1成功数增加了4个，与我们设置的burst的数目一直。具体处理流程是：1个请求被立即处理，4个请求被放到burst队列中，另外1个请求被拒绝。<strong>通过设置burst参数，我们是的Nginx限流具备了缓存处理突发流量的能力</strong>。</p>
<p>但是请注意，burst的作用是让多余的请求可以先放到队列里，慢慢处理。如果不加nodelay参数，队列里的请求<strong>不会立即处理</strong>，而是按照rate设置的速度，以毫秒级精确的速度慢慢处理。</p>
<h3 id="实验3—nodelay降级排队时间"><a href="#实验3—nodelay降级排队时间" class="headerlink" title="实验3—nodelay降级排队时间"></a>实验3—nodelay降级排队时间</h3><p>实验2中我们看到，通过设置burst参数，我们允许Nginx缓存处理一定程度的突发，多余的请求可以先放到队列里，慢慢处理，起到了平滑流量的作用。但是如果队列设置的比较大，请求排队的时间比较长，用户角度看来就是RT（<strong>响应时间 Response Time</strong>）变长了，这对用户很不友好。有什么解决办法呢？<br><strong>nodelay参数允许请求在排队的时候就立即被处理，也就是说只要请求能够进度burst队列，就会立即被后台worker处理</strong>，请注意，这意味着burst设置了nodelay是，系统瞬间的QPS可能会超过rate设置的阀值。<strong>nodelay</strong>参数要跟<strong>burst</strong>一起使用才有作用。</p>
<p>延续实验2的配置，我们加入nodelay选项：<br><img src="/images/v2-ceb16668eb99de86d5c812c9cfdbf612_720w.jpg" alt=""><br>单个IP在10ms内并发发送6个请求，结果如下：<br><img src="/images/v2-f73b1d56d201662def37be57528c60ff_720w.jpg" alt=""><br>跟实验2相比，请求成功率没变化，但是<strong>总体耗时变短了</strong>。这怎么解释呢？实验2中，有4个请求被放到burst队列当中，工作进程每隔500ms（rate=2r/s）取一个请求进行处理，最后一个请求要排队2s才会被处理；实验3中，请求放入队列和实验2是一样的，但不同的是，队列中的请求同时具有了被处理的资格，所以实验3中的5个请求可以说是同时开始被处理，花费时间自然变短了。</p>
<p>但是请注意，虽然设置burst和nodelay能够降低突发请求的处理时间，但是长期来看并不会提高吞吐量的上限，长期吞吐量的上限是由rate决定的，因为nodelay只能保证burst的请求被立即处理，但是Nginx会限制队列元素释放的速度，就像是限制了令牌桶中令牌产生的速度。</p>
<p>看到这里你可能会问，加入了nodelay参数之后的限速算法，到底算是哪一个“桶”，是漏桶算法还是令牌桶算法？当然还算是漏桶算法。考虑一种情况，令牌桶算法的token未耗尽时会怎么做呢？由于它有一个请求队列，所以会把接下来的请求缓存下来，缓存多少受限于队列大小。但此时缓存这些请求还有意义吗？如果server已经过载，缓存队列越来越长，RT越来越高，即使过了很久请求被处理，对用户来说也没有什么价值了。所以当token不够用时，最明智的做法就是直接拒绝用户的请求，这就成了漏桶算法！</p>
<h1 id="源码剖析"><a href="#源码剖析" class="headerlink" title="源码剖析"></a>源码剖析</h1><p>具体内容省略，有兴趣的同学可以参看原文或参看源码</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文主要讲解了Nginx按请求速率限速模块的用法和原理，其中burst和nodelay参数是容易引起误解的，虽然可通过burst允许缓存处理突发请求，结合nodelay能够降低突发请求的处理时间，但是长期来看他们并不会提高吞吐量的上限，长期吞吐量的上限是由rate决定的。需要特别注意的事，burst设置了nodelay时，系统时间的QPS可能会超过rate设置的阀值。</p>
]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>ITIL思想</title>
    <url>/2020/03/07/ITIL%E6%80%9D%E6%83%B3/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>ITIL</tag>
      </tags>
  </entry>
  <entry>
    <title>K8s学习笔记</title>
    <url>/2020/02/22/K8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB学习笔记</title>
    <url>/2020/02/22/MongoDB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>纪念我的父亲</title>
    <url>/2020/02/22/%E7%BA%AA%E5%BF%B5%E6%88%91%E7%9A%84%E7%88%B6%E4%BA%B2/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>SRE方法论</title>
    <url>/2020/02/21/SRE%E6%96%B9%E6%B3%95%E8%AE%BA/</url>
    <content><![CDATA[<h1 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h1><h2 id="1-确保长期关注运维研发工作"><a href="#1-确保长期关注运维研发工作" class="headerlink" title="1. 确保长期关注运维研发工作"></a>1. 确保长期关注运维研发工作</h2><ul>
<li>最多 50% 的运维值班内容，最少 50% 的运维开发内容</li>
<li>控制处理紧急事件的数量，运维人员有充分时间处理故障、恢复服务以及事后进行复盘报告</li>
<li>事前报警，但是事后总结更加重要：复盘故障发生、报警和处理的全过程，挖掘故障发生的根本原因，提供相应的预防或解决方案，对事不对人</li>
</ul>
<h2 id="2-产品稳定性和迭代速度之间的矛盾"><a href="#2-产品稳定性和迭代速度之间的矛盾" class="headerlink" title="2. 产品稳定性和迭代速度之间的矛盾"></a>2. 产品稳定性和迭代速度之间的矛盾</h2><ul>
<li>可靠性目标 SLO</li>
<li>错误预算</li>
<li>利用错误预算，加快产品迭代速度，同时保证服务质量</li>
<li>最终目标不是“零事故”，而是在稳定和迭代之间寻求平衡，开发和运维之间协作创新</li>
</ul>
<h2 id="3-监控系统"><a href="#3-监控系统" class="headerlink" title="3. 监控系统"></a>3. 监控系统</h2><ul>
<li>紧急报警（alert） ：业务正常运行受到影响，需要紧急处理</li>
<li>工单（ticket）：业务不受影响，可以延期处理</li>
<li>日志（logging）：记录应用运行日志，用于调试和事后分析</li>
</ul>
<h2 id="4-应急事件处理"><a href="#4-应急事件处理" class="headerlink" title="4. 应急事件处理"></a>4. 应急事件处理</h2><ul>
<li>MTTF（平均失败时间）</li>
<li>MTTR（平均恢复时间）</li>
<li>自动恢复系统，而非需要人工干预，可减少恢复时间</li>
<li>运维手册（playbook）</li>
</ul>
<h2 id="5-变更管理"><a href="#5-变更管理" class="headerlink" title="5. 变更管理"></a>5. 变更管理</h2><ul>
<li>渐进式发布机制（<a href="https://www.cnblogs.com/nulige/articles/10929182.html" target="_blank" rel="noopener">几种常见的发布方式</a>：<ul>
<li>蓝绿发布（AB发布）<br>将应用所在集群上的机器从逻辑上分为A/B两组。在新版发布时，首先把A组的机器从负载均衡中摘除，再进行新版本的部署。此时，B组仍然继续提供服务。<br><img src="/images/1053682-20190527095123236-652009308.png" alt=""><br>当A组升级完毕后，负载均衡重新接入A组，再把B组从负载列表中摘除，进行新版本的部署。A组重新提供服务。<br><img src="/images/1053682-20190527095313544-971610690.png" alt=""><br>特点：<ul>
<li>如果出问题，影响面较广，或者说很难控制具体的影响面</li>
<li>发布策略简单</li>
<li>用户无感知，平滑过渡</li>
<li>升级/回滚速度快<br>缺点：</li>
<li>需要准备正常业务使用资源的两倍以上服务器，防止升级期间单组无法承载业务突发</li>
<li>短时间内浪费一定资源成本</li>
<li>基础设施无改动，增大升级稳定性<br>蓝绿发布在早期物理服务器时代，还是比较昂贵的，由于云计算普及，成本也大大降低</li>
</ul>
</li>
<li>灰度发布<br>灰度发布只升级部分服务，即让一部分用户继续用老版本，一部分用户开始用新版本，如果用户对新版本没什么意见，那么逐步扩大范围，把所有用户都迁移到新版本上面来。<br><img src="/images/1053682-20190527095414439-329213436.png" alt=""><br>特点：<ul>
<li>保证整体系统稳定性，在初始灰度的时候就可以发现、调整问题，影响范围可控</li>
<li>新功能逐步评估性能，稳定性和健康状况，如果出问题影响范围很小，相对用户体验也少</li>
<li>用户无感知，平滑过渡<br>缺点：</li>
<li>自动化要求高<br>部署过程：</li>
<li>从LB摘掉灰度服务器，升级成功后再加入LB</li>
<li>少量用户流量到新版本</li>
<li>如果灰度服务器测试成功，升级剩余服务器<br>灰度发布是通过切换线上并存版本之间的路由权重，逐步从一个版本切换为另一个版本的过程</li>
</ul>
</li>
<li>滚动发布<br>滚动发布是指每次只升级一个或多个服务，升级完成后加入生产环境，不断执行这个过程，直到集群中的全部旧版本升级新版本。<br><img src="/images/1053682-20190527095443475-675603692.png" alt=""><ul>
<li>红色：正在更新的实例</li>
<li>蓝色：更新完成并加入集群的实例</li>
<li>绿色：正在运行的实例<br>特点：</li>
<li>用户无感知，平滑过渡</li>
<li>节约资源<br>缺点：</li>
<li>部署时间慢，取决于每阶段更新时间</li>
<li>发布策略较复杂</li>
<li>无法确定OK的环境，不易回滚<br>部署过程：</li>
<li>先升级1个副本，主要做部署验证</li>
<li>每次升级副本，自动从LB上摘掉，升级成功后自动加入集群</li>
<li>事先需要有自动更新策略，分为若干次，每次数量/百分比可配置</li>
<li>回滚是发布的逆过程，先从LB摘掉新版本，再升级老版本，这个过程一般时间比较长</li>
<li>自动化要求高</li>
</ul>
</li>
<li>小结<br>综上所述，三种方式均可以做到平滑式升级，在升级过程中服务仍然保持服务的连续性，升级对外界是无感知的。那生产上选择哪种部署方法最合适呢？这取决于哪种方法最适合你的业务和技术需求。如果你们运维自动化能力储备不够，肯定是越简单越好，建议蓝绿发布，如果业务对用户依赖很强，建议灰度发布。如果是K8S平台，滚动更新是现成的方案，建议先直接使用<ul>
<li>蓝绿发布：两套环境交替升级，旧版本保留一定时间便于回滚</li>
<li>灰度发布：根据比例将老版本升级，例如80%用户访问是老版本，20%用户访问是新版本</li>
<li>滚动发布：按批次停止老版本实例，启动新版本实例</li>
</ul>
</li>
</ul>
</li>
<li>迅速而准确的检测到问题的发生</li>
<li>当出现问题时，安全迅速的回退改动</li>
</ul>
<h2 id="6-需求预测和容量规划"><a href="#6-需求预测和容量规划" class="headerlink" title="6. 需求预测和容量规划"></a>6. 需求预测和容量规划</h2><p>业务的容量规划，包括自然增长（随着用户使用量上升，资源使用量也上升），也包括一些非自然增长的因素（如新功能的发布，商业推广，以及其他商业因素在内）</p>
<ul>
<li>必须有一个准确的自然增长需求预测模型，需求预测的时间应该超过资源获取的时间</li>
<li>规划中必须有准确的非自然增长的需求来源的统计</li>
<li>必须有周期性的压力测试，以便准确的将系统原始资源信息与业务容量对应起来</li>
</ul>
<h2 id="7-资源部署"><a href="#7-资源部署" class="headerlink" title="7. 资源部署"></a>7. 资源部署</h2><p>资源部署是变更管理与容量规划的结合产物。</p>
<ul>
<li>资源部署和配置必须迅速完成</li>
<li>仅在必要的时候执行，因为资源有限且昂贵</li>
<li>保证部署和配置过程执行的正确性，否则资源不可用</li>
<li>部署和配置过程影响较大，会有较大幅度修改，必须执行一系列测试，确保可以正确的提供服务</li>
</ul>
<h2 id="8-效率与性能"><a href="#8-效率与性能" class="headerlink" title="8. 效率与性能"></a>8. 效率与性能</h2><ul>
<li>高效的利用资源，盈利的必要性</li>
<li>SRE负责容量的部署和配置，承担有关利用率的讨论和改进</li>
<li>服务的利用率指标依赖于服务的工作方式和对容量的配置与部署</li>
<li>关注服务的容量配置策略，提升资源利用率，可以有效的降低系统成本<br>业务总体资源的使用情况的关键驱动因素：<ul>
<li>用户需求</li>
<li>可用容量</li>
<li>软件的资源使用效率<br>SRE可以通过模型预测用户需求，合理部署和配置可用容量，同时可以改进软件以提升资源的使用效率。通过这三个因素可以大幅度提升服务的效率。<br>软件系统一般来说在负载上升的时候，会导致延迟升高。延迟升高其实和容量损失是一样的。当负载达到临界线的时候，一个逐渐变慢的系统最终会停止一切服务。SRE的目标是根据一个预设的延迟目标，部署和维护足够的容量。SRE和研发团队应该共同监控和优化整个系统的性能，这就相当于给服务增加容量和提升效率了。</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>SRE</tag>
      </tags>
  </entry>
  <entry>
    <title>MarkDown常用语法</title>
    <url>/2020/02/20/MarkDown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<p>一、标题<br><code># 一级标题</code><br><code>## 二级标题</code><br><code>### 三级标题</code><br><code>### 四级标题</code><br><code>##### 五级标题</code><br><code>###### 六级标题</code><br><strong>【最多六级】</strong></p>
<p>二、字体<br><strong>加粗文字</strong><br><em>倾斜文字</em><br><strong><em>加粗倾斜文字</em></strong><br><del>删除线文字</del></p>
<p>三、引用</p>
<blockquote>
<p>引用</p>
<blockquote>
<p>引用</p>
<blockquote>
<p>引用</p>
</blockquote>
</blockquote>
</blockquote>
<p>四、分割线</p>
<hr>
<hr>
<hr>
<hr>
<p>五、图片</p>
<p>![图片alt](图片地址 ‘’图片title’’)</p>
<p><img src="https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=702257389,1274025419&fm=27&gp=0.jpg" alt="blockchain" title="区块链"></p>
<p>六、超链接<br><a href="超链接地址" title="超链接title">超链接名</a><br>title可加可不加</p>
<p>七、列表<br>无序列表</p>
<ul>
<li>a</li>
</ul>
<ul>
<li>b</li>
</ul>
<ul>
<li>c</li>
</ul>
<p>有序列表</p>
<ol>
<li>a</li>
<li>b</li>
<li>c</li>
</ol>
<p>注意序号和内容之间的空格</p>
<p>列表嵌套：上下级列表使用3个空格</p>
<ul>
<li>a<ul>
<li>b<ul>
<li>c</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>十、流程图</p>
<p>`` <div id="flowchart-0" class="flow-chart"></div></p>
<div id="flowchart-1" class="flow-chart"></div><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">`` st=>start: 开始
`` op=>operation: My Operation
`` cond=>condition: Yes or No?
`` e=>end
`` st->op->cond
`` cond(yes)->e
`` cond(no)->op
`` &</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script><textarea id="flowchart-1-code" style="display: none">st=>start: 开始
op=>operation: My Operation
cond=>condition: Yes or No?
e=>end
st->op->cond
cond(yes)->e
cond(no)->op
&</textarea><textarea id="flowchart-1-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-1-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-1", options);</script>]]></content>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>运维思考</title>
    <url>/2020/02/20/opsthink/</url>
    <content><![CDATA[<h1 id="运维管理思考"><a href="#运维管理思考" class="headerlink" title="运维管理思考"></a>运维管理思考</h1><h2 id="技术管理"><a href="#技术管理" class="headerlink" title="技术管理"></a>技术管理</h2>]]></content>
      <tags>
        <tag>ops</tag>
      </tags>
  </entry>
  <entry>
    <title>AboutMe</title>
    <url>/2020/02/17/AboutMe/</url>
    <content><![CDATA[<h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2>]]></content>
  </entry>
</search>
